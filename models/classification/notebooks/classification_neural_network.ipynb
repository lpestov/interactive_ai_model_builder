{
 "cells": [
  {
   "metadata": {
    "id": "aa68699bebffa450"
   },
   "cell_type": "markdown",
   "source": [
    "## Выбор модели для задач классификации\n",
    "\n",
    "Для задач классификации существует несколько способов выбора модели:\n",
    "\n",
    "1. **Обучить маленькую модель с нуля**: Выбор легковесной архитектуры модели и полное обучение её на нашем наборе данных.\n",
    "2. **Fine-Tuning предобученной модели**: Используем модель, которая была предобучена авторами на другом наборе данных, и только последние слои переобучается на нашем конкретном наборе данных.\n",
    "3. **Использовать предобученные веса напрямую**: В этом методе используется предобученная модель без дополнительного обучения.\n",
    "\n",
    "Лучшим вариантом является Fine-Tuning, поэтому в качестве бейзлайна возьмем маленькую (5.3M) EfficientNet B0 с претрейновыми параметрами\n",
    "\n",
    "[Оригинальная статья](https://arxiv.org/abs/1905.11946)"
   ],
   "id": "aa68699bebffa450"
  },
  {
   "metadata": {
    "id": "64d51ba3c49092bf"
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "64d51ba3c49092bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json"
   ],
   "metadata": {
    "id": "FkfKf0m2DMYi"
   },
   "id": "FkfKf0m2DMYi",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySNAui8JDR_0",
    "outputId": "d3cf8f45-499e-4423-93b2-3069d9d3102c"
   },
   "id": "ySNAui8JDR_0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Загрузка гиперпараметров из JSON (создайте папку classification, если её еще нет в корне диска Google Drive)\n",
    "with open('/content/drive/MyDrive/classification/hyperparams.json', \"r\") as f:\n",
    "  hyperparams = json.load(f)"
   ],
   "metadata": {
    "id": "taGAid8FlvSK"
   },
   "id": "taGAid8FlvSK",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Загрузка названий классов из JSON\n",
    "with open(\"/content/drive/MyDrive/classification/class_to_idx.json\", \"r\")  as f:\n",
    "  class_to_idx = json.load(f)"
   ],
   "metadata": {
    "id": "49Y_q4czz1_A"
   },
   "id": "49Y_q4czz1_A",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Структура** c*lassification_dataset.zip*: (внутри папка с таким же названием)\n",
    "\n",
    "```\n",
    "classification_dataset/\n",
    "├── train/\n",
    "│   ├── class_name1/\n",
    "│   └── class_name2/\n",
    "│   └── ...\n",
    "\n",
    "└── test/\n",
    "    ├── class_name1/\n",
    "    └── class_name2/\n",
    "    └── ...\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "8hR_BEbW2__5"
   },
   "id": "8hR_BEbW2__5"
  },
  {
   "cell_type": "code",
   "source": [
    "local_zip = '/content/drive/MyDrive/classification/classification_dataset.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/content/dataset')\n",
    "zip_ref.close()"
   ],
   "metadata": {
    "id": "YP3zUyAgDjuG"
   },
   "id": "YP3zUyAgDjuG",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Класс для аугментации данных\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, original_folder, target_size=50, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "        # Проверяем, что все классы из JSON есть в папке\n",
    "        class_names = os.listdir(original_folder)\n",
    "        missing_classes = [cls for cls in class_to_idx.keys() if cls not in class_names]\n",
    "        if missing_classes:\n",
    "            raise ValueError(f\"Классы {missing_classes} из class_to_idx.json отсутствуют в папке {original_folder}\")\n",
    "\n",
    "        # Собираем пути к изображениям для каждого класса\n",
    "        for class_name in class_names: # Используем отсортированные имена классов\n",
    "            class_path = os.path.join(original_folder, class_name)\n",
    "            images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "            # Повторяем изображения до достижения целевого размера\n",
    "            for i in range(target_size):\n",
    "                self.samples.append((images[i % len(images)], class_name))\n",
    "\n",
    "    # Возвращает общее количество элементов в наборе данных\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    # Возвращает одно изображение и его метку по индексу\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Применяем аугментации\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Преобразуем метку класса в числовой формат\n",
    "        label = self.class_to_idx[class_name]  # Преобразуем имя класса в индекс\n",
    "        return image, label  # Оставляем числовую метку для обучения"
   ],
   "metadata": {
    "id": "euJom3Xtrqyw"
   },
   "id": "euJom3Xtrqyw",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Класс для создания датасета под Test выборку\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, original_folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = class_to_idx  # Загружаем метки классов из JSON\n",
    "\n",
    "        # Проверяем, что все классы из JSON есть в папке\n",
    "        class_names = os.listdir(original_folder)\n",
    "        missing_classes = [cls for cls in class_to_idx.keys() if cls not in class_names]\n",
    "        if missing_classes:\n",
    "            raise ValueError(f\"Классы {missing_classes} из class_to_idx.json отсутствуют в {original_folder}\")\n",
    "\n",
    "        # Собираем пути к изображениям\n",
    "        for class_name in class_names:\n",
    "            class_path = os.path.join(original_folder, class_name)\n",
    "            images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "            for img_path in images:\n",
    "                self.samples.append((img_path, class_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Применяем трансформации (без аугментаций)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Преобразуем имя класса в индекс\n",
    "        label = self.class_to_idx[class_name]\n",
    "        return image, label"
   ],
   "metadata": {
    "id": "S5LFWrXGMlpC"
   },
   "id": "S5LFWrXGMlpC",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Трансформы с аугментациями для тренировочных данных\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Трансформы для тестовых данных\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Создание аугментированных датасетов\n",
    "train_dataset = AugmentedDataset(\n",
    "    original_folder='/content/dataset/classification_dataset/train',\n",
    "    target_size=50,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = TestDataset(\n",
    "    original_folder='/content/dataset/classification_dataset/test',\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "\n",
    "# DataLoader'ы\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=hyperparams['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=hyperparams['batch_size'],\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "id": "yNKltStG526A"
   },
   "id": "yNKltStG526A",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Проверим классы\n",
    "test_dataset.class_to_idx"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InprTrqIYl_c",
    "outputId": "95544549-e615-438c-c751-9d8c4d5e36bb"
   },
   "id": "InprTrqIYl_c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Создание обратного словаря idx_to_class\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}"
   ],
   "metadata": {
    "id": "cn5UPHMGK0zD"
   },
   "id": "cn5UPHMGK0zD",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Проверим классы\n",
    "print(train_dataset.class_to_idx)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ebA1VDo5Za_",
    "outputId": "c2363d42-18bf-4274-81a2-be922f1b8c32"
   },
   "id": "2ebA1VDo5Za_",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Загрузка модели EfficientNet\n",
    "model = efficientnet_b0(EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "# Заморозка всех слоев, кроме последнего\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Замена финального классификатора\n",
    "num_features = model.classifier[1].in_features\n",
    "num_classes = len(class_to_idx)  # Количество классов из JSON\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, num_classes),  # Многоклассовая классификация\n",
    "    # На выходе оставляем сырые логиты, так как nn.CrossEntropyLoss() их ожидает на вход\n",
    ")"
   ],
   "metadata": {
    "id": "G_aEiUeyGrWq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f3a8cfae-7045-466b-a6b9-0dab0cbdd95c"
   },
   "id": "G_aEiUeyGrWq",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Для многоклассовой классификации\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=hyperparams['learning_rate'],\n",
    "    weight_decay=hyperparams['weight_decay']\n",
    ")"
   ],
   "metadata": {
    "id": "QkRyX0igHntl"
   },
   "id": "QkRyX0igHntl",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Обучение модели\n",
    "for epoch in range(hyperparams['num_epochs']):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Получаем индекс максимального значения\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Вывод статистики\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    val_loss = val_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{hyperparams['num_epochs']}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJW_VuPoHh74",
    "outputId": "9b3a60ad-9e56-4e2a-ed3d-fb6696cfd381"
   },
   "id": "LJW_VuPoHh74",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Сохранение модели\n",
    "torch.save(model, '/content/trained_model_classification.pt')\n",
    "\n",
    "# Копирование на Google Drive\n",
    "!cp \"/content/trained_model_classification.pt\" \"/content/drive/MyDrive/classification/trained_model_classification.pt\"\n",
    "print(\"Модель сохранена\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-ybRMlizfsy",
    "outputId": "9b49bd65-f3e3-4080-c6cb-0c920047b2c7"
   },
   "id": "B-ybRMlizfsy",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
