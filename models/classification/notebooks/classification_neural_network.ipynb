{
  "cells": [
    {
      "metadata": {
        "id": "aa68699bebffa450"
      },
      "cell_type": "markdown",
      "source": [
        "## Выбор модели для задач классификации\n",
        "\n",
        "Для задач классификации существует несколько способов выбора модели:\n",
        "\n",
        "1. **Обучить маленькую модель с нуля**: Выбор легковесной архитектуры модели и полное обучение её на нашем наборе данных.\n",
        "2. **Fine-Tuning предобученной модели**: Используем модель, которая была предобучена авторами на другом наборе данных, и только последние слои переобучается на нашем конкретном наборе данных.\n",
        "3. **Использовать предобученные веса напрямую**: В этом методе используется предобученная модель без дополнительного обучения.\n",
        "\n",
        "Лучшим вариантом является Fine-Tuning, поэтому в качестве бейзлайна возьмем маленькую (5.3M) EfficientNet B0 с претрейновыми параметрами\n",
        "\n",
        "[Оригинальная статья](https://arxiv.org/abs/1905.11946)"
      ],
      "id": "aa68699bebffa450"
    },
    {
      "metadata": {
        "id": "64d51ba3c49092bf"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 1,
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "from PIL import Image"
      ],
      "id": "64d51ba3c49092bf"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import json"
      ],
      "metadata": {
        "id": "FkfKf0m2DMYi"
      },
      "id": "FkfKf0m2DMYi",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "87muylyZAP05"
      },
      "id": "87muylyZAP05",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySNAui8JDR_0",
        "outputId": "2233820e-789f-4c9d-9fc5-cb7779bcade2"
      },
      "id": "ySNAui8JDR_0",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка гиперпараметров из JSON (создайте папку classification, если её еще нет в корне диска Google Drive)\n",
        "with open('/content/drive/MyDrive/classification/hyperparams.json', \"r\") as f:\n",
        "  hyperparams = json.load(f)"
      ],
      "metadata": {
        "id": "taGAid8FlvSK"
      },
      "id": "taGAid8FlvSK",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Структура** c*lassification_dataset.zip*: (внутри папка с таким же названием)\n",
        "\n",
        "```\n",
        "classification_dataset/\n",
        "├── train/\n",
        "│   ├── 0/\n",
        "│   └── 1/\n",
        "└── test/\n",
        "    ├── 0/\n",
        "    └── 1/\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "8hR_BEbW2__5"
      },
      "id": "8hR_BEbW2__5"
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip = '/content/drive/MyDrive/classification/classification_dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/dataset')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "YP3zUyAgDjuG"
      },
      "id": "YP3zUyAgDjuG",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Класс для аугментации данных\n",
        "class AugmentedDataset(Dataset):\n",
        "    def __init__(self, original_folder, target_size=50, transform=None):\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self.class_to_idx = {}\n",
        "\n",
        "        class_names = sorted(os.listdir(original_folder)) # Получаем отсортированный список имен классов\n",
        "        for idx, class_name in enumerate(class_names): # Итерируемся и присваиваем индексы\n",
        "            self.class_to_idx[class_name] = idx\n",
        "\n",
        "        # Собираем пути к изображениям для каждого класса\n",
        "        for class_name in class_names: # Используем отсортированные имена классов\n",
        "            class_path = os.path.join(original_folder, class_name)\n",
        "            images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
        "            # Повторяем изображения до достижения целевого размера\n",
        "            for i in range(target_size):\n",
        "                self.samples.append((images[i % len(images)], class_name))\n",
        "\n",
        "    # Возвращает общее количество элементов в наборе данных\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    # Возвращает одно изображение и его метку по индексу\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, class_name = self.samples[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Применяем аугментации\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Преобразуем метку класса в числовой формат\n",
        "        label_str = class_name # Метка класса все еще строка\n",
        "        label = self.class_to_idx[label_str] # Используем class_to_idx для получения числового индекса\n",
        "        return image, torch.tensor(label, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "euJom3Xtrqyw"
      },
      "id": "euJom3Xtrqyw",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Трансформы с аугментациями для тренировочных данных\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Трансформы для тестовых данных\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Создание аугментированных датасетов\n",
        "train_dataset = AugmentedDataset(\n",
        "    original_folder='/content/dataset/classification_dataset/train',\n",
        "    target_size=50,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    '/content/dataset/classification_dataset/test',\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "# DataLoader'ы\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=hyperparams['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=hyperparams['batch_size'],\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "yNKltStG526A"
      },
      "id": "yNKltStG526A",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим классы\n",
        "print(train_dataset.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ebA1VDo5Za_",
        "outputId": "a0aadbb1-7955-46a0-f9f4-bc9082b08d1d"
      },
      "id": "2ebA1VDo5Za_",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': 0, '1': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели EfficientNet\n",
        "model = efficientnet_b0(EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "# Заморозка всех слоев, кроме последнего\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Замена финального классификатора\n",
        "num_features = model.classifier[1].in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_features, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1),  # Бинарная классификация\n",
        "    nn.Sigmoid()        # Для вероятностей\n",
        ")"
      ],
      "metadata": {
        "id": "G_aEiUeyGrWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6bd333-813b-46d6-cda7-67554a1362f5"
      },
      "id": "G_aEiUeyGrWq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 43.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()  # Для бинарной классификации\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=hyperparams['learning_rate'],\n",
        "    weight_decay=hyperparams['weight_decay']\n",
        ")"
      ],
      "metadata": {
        "id": "QkRyX0igHntl"
      },
      "id": "QkRyX0igHntl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "for epoch in range(hyperparams['num_epochs']):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float()\n",
        "\n",
        "            outputs = model(images).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    # Вывод статистики\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    val_loss = val_loss / len(test_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{hyperparams['num_epochs']}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJW_VuPoHh74",
        "outputId": "e14b5c79-beca-4412-8f5b-4ea6356c8b32"
      },
      "id": "LJW_VuPoHh74",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Train Loss: 0.6868, Val Loss: 0.6652, Accuracy: 0.7900\n",
            "Epoch 2/10\n",
            "Train Loss: 0.6343, Val Loss: 0.6405, Accuracy: 0.8680\n",
            "Epoch 3/10\n",
            "Train Loss: 0.6046, Val Loss: 0.6199, Accuracy: 0.8740\n",
            "Epoch 4/10\n",
            "Train Loss: 0.5463, Val Loss: 0.5986, Accuracy: 0.8800\n",
            "Epoch 5/10\n",
            "Train Loss: 0.5169, Val Loss: 0.5565, Accuracy: 0.8950\n",
            "Epoch 6/10\n",
            "Train Loss: 0.4488, Val Loss: 0.5336, Accuracy: 0.9010\n",
            "Epoch 7/10\n",
            "Train Loss: 0.4102, Val Loss: 0.5096, Accuracy: 0.8950\n",
            "Epoch 8/10\n",
            "Train Loss: 0.3712, Val Loss: 0.4839, Accuracy: 0.8970\n",
            "Epoch 9/10\n",
            "Train Loss: 0.3392, Val Loss: 0.4623, Accuracy: 0.8910\n",
            "Epoch 10/10\n",
            "Train Loss: 0.3108, Val Loss: 0.4429, Accuracy: 0.8940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение модели\n",
        "torch.save(model, '/content/trained_model_classification.pt')\n",
        "\n",
        "# Копирование на Google Drive\n",
        "!cp \"/content/trained_model_classification.pt\" \"/content/drive/MyDrive/classification/trained_model_classification.pt\"\n",
        "print(\"Модель сохранена\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-ybRMlizfsy",
        "outputId": "5c44dab3-c15f-4acf-92b1-86726e654544"
      },
      "id": "B-ybRMlizfsy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель сохранена\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}